{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from easydict import EasyDict as edict\n",
    "from dataset_manager_optimized import DatasetManager\n",
    "from preprocessing.bucketing import get_bucketer\n",
    "from preprocessing.encoding import get_encoder\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id_col = \"Case ID\"\n",
    "activity_col = \"Activity\"\n",
    "resource_col = 'org:resource'\n",
    "timestamp_col = 'time:timestamp'\n",
    "label_col = \"label\"\n",
    "pos_label = \"deviant\"\n",
    "neg_label = \"regular\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for classifier\n",
    "# Categorical features \n",
    "dynamic_cat_cols = [activity_col, resource_col, 'Action', 'CreditScore', 'EventOrigin', 'lifecycle:transition',\n",
    "                   \"Accepted\", \"Selected\"] # i.e. event attributes\n",
    "static_cat_cols = ['ApplicationType', 'LoanGoal'] # i.e. case attributes that are known from the start\n",
    "\n",
    "# Numeric features\n",
    "dynamic_num_cols = ['FirstWithdrawalAmount', 'MonthlyCost', 'NumberOfTerms', 'OfferedAmount',\n",
    "                   \"timesincelastevent\", \"timesincecasestart\", \"timesincemidnight\", \"event_nr\", \"month\", \"weekday\", \"hour\",\n",
    "                    \"open_cases\"]\n",
    "static_num_cols = ['RequestedAmount']\n",
    "\n",
    "static_cols = static_cat_cols + static_num_cols + [case_id_col, label_col]\n",
    "dynamic_cols = dynamic_cat_cols + dynamic_num_cols + [timestamp_col]\n",
    "cat_cols = dynamic_cat_cols + static_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = edict({'case_id_col': case_id_col,\n",
    "                           'activity_col': activity_col,\n",
    "                           'resource_col': resource_col,\n",
    "                           'timestamp_col': timestamp_col,\n",
    "                           'label_col': label_col,\n",
    "                           'pos_label_col': pos_label,\n",
    "                           'dynamic_cat_cols': dynamic_cat_cols,\n",
    "                           'static_cat_cols': static_cat_cols,\n",
    "                           'dynamic_num_cols': dynamic_num_cols,\n",
    "                           'static_num_cols': static_num_cols,\n",
    "                'min_prefix_length': 1,\n",
    "                'max_prefix_length': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DatasetColumnSchema.__init__() got an unexpected keyword argument 'pos_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m ds_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbpic2017\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m      6\u001b[0m ds_file_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBPIC17_O_Accepted.csv\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;66;03m#, 'BPIC17_O_Cancelled.csv', 'BPIC17_O_Refused.csv']\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m bpic17_column_schema \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetSchemas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbpic2017\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m bucketing_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m encoding_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/vsc-hard-mounts/leuven-data/365/vsc36567/xAI-PPM/dataset_column_schema.py:195\u001b[0m, in \u001b[0;36mDatasetSchemas.bpic2017\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbpic2017\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DatasetColumnSchema:\n\u001b[1;32m    194\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schema for BPIC 2017 dataset\"\"\"\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatasetColumnSchema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_id_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCase ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivity_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mActivity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morg:resource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestamp_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime:timestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeviant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneg_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregular\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_cat_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mActivity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morg:resource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCreditScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEventOrigin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlifecycle:transition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAccepted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSelected\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_cat_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mApplicationType\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLoanGoal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_num_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFirstWithdrawalAmount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonthlyCost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNumberOfTerms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOfferedAmount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimesincelastevent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimesincecasestart\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimesincemidnight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevent_nr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweekday\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhour\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopen_cases\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_num_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRequestedAmount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: DatasetColumnSchema.__init__() got an unexpected keyword argument 'pos_label'"
     ]
    }
   ],
   "source": [
    "from dataset_column_schema import DatasetSchemas \n",
    "\n",
    "\n",
    "data_dir = '/data/leuven/365/vsc36567/xAI-PPM/data/processed_benchmark_event_logs'\n",
    "ds_name = 'bpic2017' \n",
    "ds_file_names = ['BPIC17_O_Accepted.csv']#, 'BPIC17_O_Cancelled.csv', 'BPIC17_O_Refused.csv']\n",
    "bpic17_column_schema = DatasetSchemas.bpic2017()\n",
    "\n",
    "bucketing_method = 'single'\n",
    "encoding_method = 'agg'\n",
    "encoding_dict = {\n",
    "            \"laststate\": [\"static\", \"last\"],\n",
    "            \"agg\": [\"static\", \"agg\"],\n",
    "            \"index\": [\"static\", \"index\"],\n",
    "            \"combined\": [\"static\", \"last\", \"agg\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the path to your 'processed_benchmark_event_logs' folder \n",
    "data_dir = r'/data/leuven/365/vsc36567/xAI-PPM/data/processed_benchmark_event_logs' \n",
    "\n",
    "# dataset  #\"BPIC2017_O_Cancelled\", \"BPIC2017_O_Refused\"] were commented to fit the encoded data into available memory \n",
    "dataset_ref_to_datasets = {\n",
    "    \"bpic2017\" : [\"BPIC17_O_Accepted\"]#, \"BPIC2017_O_Cancelled\", \"BPIC2017_O_Refused\"],\n",
    "}\n",
    "\n",
    "bucketing = 'single'\n",
    "encoding = 'agg'\n",
    "method_name = ('_').join([bucketing, encoding])\n",
    "\n",
    "encoding_dict = {\n",
    "    'agg' : ['static', 'agg'],\n",
    "    'index' : ['static', 'index']\n",
    "    }\n",
    "\n",
    "gap = 1\n",
    "train_ratio = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe, fmin, hp\n",
    "import hyperopt\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "import time \n",
    "import sys\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetColumnSchema' object has no attribute 'pos_label_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m dataset_ref_to_datasets[dataset_name]:\n\u001b[1;32m     18\u001b[0m     activity \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 19\u001b[0m     dm \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbpic17_column_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     df \u001b[38;5;241m=\u001b[39m dm\u001b[38;5;241m.\u001b[39mread_dataset(osp\u001b[38;5;241m.\u001b[39mjoin(data_dir, file_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     21\u001b[0m     max_prefix_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(config\u001b[38;5;241m.\u001b[39mmax_prefix_length, dm\u001b[38;5;241m.\u001b[39mget_pos_case_length_quantile(df, \u001b[38;5;241m0.90\u001b[39m))\n",
      "File \u001b[0;32m/vsc-hard-mounts/leuven-data/365/vsc36567/xAI-PPM/dataset_manager_optimized.py:20\u001b[0m, in \u001b[0;36mDatasetManager.__init__\u001b[0;34m(self, ds_name, ds_column_schema)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimestamp \u001b[38;5;241m=\u001b[39m ds_column_schema\u001b[38;5;241m.\u001b[39mtimestamp_col\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m=\u001b[39m ds_column_schema\u001b[38;5;241m.\u001b[39mlabel_col\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_label \u001b[38;5;241m=\u001b[39m \u001b[43mds_column_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_label_col\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_cat_cols \u001b[38;5;241m=\u001b[39m ds_column_schema\u001b[38;5;241m.\u001b[39mdynamic_cat_cols\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_cat_cols \u001b[38;5;241m=\u001b[39m ds_column_schema\u001b[38;5;241m.\u001b[39mstatic_cat_cols\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetColumnSchema' object has no attribute 'pos_label_col'"
     ]
    }
   ],
   "source": [
    "# Read the datasets\n",
    "# DataManager splits the data and extracts prefixes \n",
    "\n",
    "dataset_name = 'bpic2017'\n",
    "train_prefixes = {}\n",
    "test_prefixes = {}\n",
    "\n",
    "encoder_config = bpic17_column_schema.get_encoder_args(fillna=True)\n",
    "# encoder_config = {'case_id_col': case_id_col,\n",
    "#                 'static_cat_cols': static_cat_cols,\n",
    "#                 'static_num_cols': static_num_cols,\n",
    "#                 'dynamic_cat_cols': dynamic_cat_cols,\n",
    "#                 'dynamic_num_cols': dynamic_num_cols,\n",
    "#                 'fillna': True}\n",
    "\n",
    "start_time = time.time()\n",
    "for file_name in dataset_ref_to_datasets[dataset_name]:\n",
    "    activity = file_name.split('_')[-1]\n",
    "    dm = DatasetManager(dataset_name, bpic17_column_schema)\n",
    "    df = dm.read_dataset(osp.join(data_dir, file_name + '.csv'))\n",
    "    max_prefix_length = min(config.max_prefix_length, dm.get_pos_case_length_quantile(df, 0.90))\n",
    "\n",
    "    # Splitting the data into train and test set \n",
    "    train, test = dm.split_data_strict(df, train_ratio=train_ratio, split='temporal')\n",
    "    print('Shape of the train set: ', train.shape, '\\nShape of the test set: ', test.shape)\n",
    "    \n",
    "    # Generating prefixes \n",
    "    df_train_prefixes = dm.generate_prefix_data(train, min_prefix_length, max_prefix_length)\n",
    "    df_test_prefixes = dm.generate_prefix_data(test, min_prefix_length, max_prefix_length)\n",
    "    \n",
    "    # Create buckets for each prexif or a single one that fits all the prexifes  \n",
    "    bucketer = get_bucketer(method=bucketing, case_id_col=case_id_col)\n",
    "    train_bucket = bucketer.fit_predict(df_train_prefixes)\n",
    "    test_bucket = bucketer.predict(df_test_prefixes)\n",
    "\n",
    "    # Iterating over the set of generated buckets\n",
    "    for bucket in set(test_bucket):\n",
    "\n",
    "        train_bucket_ind = dm.get_indexes(df_train_prefixes)[bucket == train_bucket]\n",
    "        test_bucket_ind = dm.get_indexes(df_test_prefixes)[bucket == test_bucket]   \n",
    "\n",
    "        # extracting training data for the experiment\n",
    "        df_train_bucket = dm.get_data_by_indexes(df_train_prefixes, train_bucket_ind)\n",
    "        df_test_bucket = dm.get_data_by_indexes(df_test_prefixes, test_bucket_ind)\n",
    "        \n",
    "        _, train_y = np.asarray(dm.get_labels(df_train_bucket))\n",
    "        _, test_y = np.asarray(dm.get_labels(df_test_bucket))\n",
    "\n",
    "        # Get a set of encoders for preprocessing of static and dynamic features\n",
    "        featureCombinerExperiment = FeatureUnion(\n",
    "                [(enc_method, get_encoder(enc_method, **encoder_config)) for enc_method in encoding_dict[encoding]])\n",
    "        \n",
    "        encoded_train_bucket = featureCombinerExperiment.fit_transform(df_train_bucket)\n",
    "        encoded_test_bucket = featureCombinerExperiment.fit_transform(df_test_bucket)        \n",
    "\n",
    "\n",
    "        enc_fnames = []\n",
    "        for _, transformer in featureCombinerExperiment.transformer_list:\n",
    "            for new_fname in transformer.get_feature_names():\n",
    "                enc_fnames.append(new_fname)\n",
    "        # enc_fnames.append('encoded_label')\n",
    "\n",
    "        # create a dataframe with the encoded training features and label\n",
    "        # encoded_training = np.concatenate((encoded_training, train_y.reshape(-1, 1)), axis=1)\n",
    "        training_set_df = pd.DataFrame(encoded_training, columns=enc_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train set encoding, commented for the test set for the sake of allocated memory\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
