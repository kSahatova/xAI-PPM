{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "956eb916",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd67568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from skpm import event_logs\n",
    "\n",
    "from ppm.datasets import ContinuousTraces\n",
    "from ppm.datasets.event_logs import EventFeatures, EventLog, EventTargets\n",
    "from ppm.datasets.utils import continuous\n",
    "from ppm.models import NextEventPredictor\n",
    "from ppm.engine.utils import load_checkpoint\n",
    "\n",
    "from model_training.utils import parse_args, get_model_config, prepare_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e89e2",
   "metadata": {},
   "source": [
    "# Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b16a37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "NUMERICAL_FEATURES = [\n",
    "    \"accumulated_time\",\n",
    "    \"day_of_month\",\n",
    "    \"day_of_week\",\n",
    "    \"day_of_year\",\n",
    "    \"hour_of_day\",\n",
    "    \"min_of_hour\",\n",
    "    \"month_of_year\",\n",
    "    \"sec_of_min\",\n",
    "    \"secs_within_day\",\n",
    "    \"week_of_year\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9c3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "\n",
    "config = {\n",
    "    # args to pop before logging\n",
    "    \"project_name\": args.project_name,\n",
    "    \"checkpoint_path\": args.checkpoint_path,\n",
    "    # args to log\n",
    "    \"log\": args.dataset,\n",
    "    \"device\": args.device,\n",
    "    # architecture\n",
    "    \"backbone\": args.backbone,\n",
    "    \"rnn_type\": args.rnn_type,\n",
    "    \"embedding_size\": args.embedding_size,\n",
    "    \"hidden_size\": args.hidden_size,\n",
    "    \"n_layers\": args.n_layers,\n",
    "    # hyperparameters\n",
    "    \"batch_size\": args.batch_size,       \n",
    "    # features and tasks\n",
    "    \"categorical_features\": args.categorical_features,\n",
    "    \"continuous_features\": (\n",
    "        NUMERICAL_FEATURES\n",
    "        if (\n",
    "            args.continuous_features is not None\n",
    "            and \"all\" in args.continuous_features\n",
    "        )\n",
    "        else args.continuous_features\n",
    "    ),\n",
    "    \"categorical_targets\": args.categorical_targets,\n",
    "    \"continuous_targets\": args.continuous_targets,\n",
    "    \"strategy\": args.strategy,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7882c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = getattr(event_logs, config[\"log\"])()\n",
    "train, test = prepare_data(\n",
    "    log.dataframe, log.unbiased_split_params, NUMERICAL_FEATURES\n",
    ")  # this is my current code for the fine-tuning experiments\n",
    "event_features = EventFeatures(\n",
    "    categorical=config[\"categorical_features\"],\n",
    "    numerical=config[\"continuous_features\"],\n",
    ")\n",
    "event_targets = EventTargets(\n",
    "    categorical=config[\"categorical_targets\"],\n",
    "    numerical=config[\"continuous_targets\"],\n",
    ")\n",
    "\n",
    "train_log = EventLog(\n",
    "    dataframe=train,\n",
    "    case_id=\"case_id\",\n",
    "    features=event_features,\n",
    "    targets=event_targets,\n",
    "    train_split=True,\n",
    "    name=config[\"log\"],\n",
    ")\n",
    "\n",
    "test_log = EventLog(\n",
    "    dataframe=test,\n",
    "    case_id=\"case_id\",\n",
    "    features=event_features,\n",
    "    targets=event_targets,\n",
    "    train_split=False,\n",
    "    name=config[\"log\"],\n",
    "    vocabs=train_log.get_vocabs(),\n",
    ")\n",
    "\n",
    "dataset_device = (\n",
    "    config[\"device\"]\n",
    "    if config[\"backbone\"]\n",
    "    not in [\"gpt2\", \"llama32-1b\", \"llama2-7b\", \"qwen25-05b\"]\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "train_dataset = ContinuousTraces(\n",
    "    log=train_log,\n",
    "    refresh_cache=True,\n",
    "    device=dataset_device,\n",
    ")\n",
    "test_dataset = ContinuousTraces(\n",
    "    log=test_log,\n",
    "    refresh_cache=True,\n",
    "    device=dataset_device,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=continuous,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=continuous,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "736b42d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Loading checkpoint from D:/PycharmProjects/xAI-PPM/persisted_models/suffix/BPI17_lstm_25epochs_num_features_preserved.pth succeed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahat\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading a pre-trained model\n",
    "model_config = get_model_config(test_log, config)\n",
    "\n",
    "model = NextEventPredictor(**model_config).to(device=config[\"device\"])\n",
    "ckpt = load_checkpoint(config[\"checkpoint_path\"], map_location=config[\"device\"])\n",
    "model.load_state_dict(ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4d8fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following 185 cases that derived \"O_Cancelled\" prediction for the next activity will be explained\n"
     ]
    }
   ],
   "source": [
    "# Extracting sequences that predicted to have \"O_Accepted\" as the next activity of the given trace\n",
    "\n",
    "o_cancelled_token = 14\n",
    "o_cancelled_ids = []\n",
    "o_cancelled_cases = []\n",
    "\n",
    "\n",
    "for ind, batch in enumerate(test_loader):\n",
    "    x_cat, x_num, _, _ = batch # type: ignore\n",
    "    x_cat, x_num = x_cat[:, :-1, :], x_num[:, :-1, :]\n",
    "    x_cat, x_num = (x_cat.to(dataset_device), x_num.to(dataset_device))\n",
    "\n",
    "    attention_mask = (x_cat[..., 0] != 0).long()\n",
    "    out, _ = model(x_cat=x_cat, x_num=x_num, attention_mask=attention_mask)\n",
    "    pred_last_event = torch.argmax(out['next_activity'][:, -1, :]).cpu().item()\n",
    "    # print(pred_last_event)\n",
    "    if pred_last_event == o_cancelled_token:\n",
    "        o_cancelled_ids.append(ind)     \n",
    "        case_to_explain = np.concatenate([x_cat.numpy(), x_num.numpy()], axis=-1)\n",
    "        o_cancelled_cases.append(case_to_explain)     \n",
    "\n",
    "print(f'The following {len(o_cancelled_cases)} cases that derived \"O_Cancelled\" prediction for the next activity will be explained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18decc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a070e80",
   "metadata": {},
   "source": [
    "# Generate prototype explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f1af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from map.map_explainer import Explainer\n",
    "from map.utils import ConceptProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbddcda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('D:/PycharmProjects/xAI-PPM/output')\n",
    "explainer_name = 'map_explainer'\n",
    "\n",
    "output_dir_ex = output_dir / explainer_name\n",
    "output_dir_ex.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "n_concepts = 4\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "exp = Explainer(input_shape=np.shape(train.X[0]),\n",
    "                output_directory=output_dir_ex,\n",
    "                n_concepts=n_concepts,\n",
    "                latent_dim=n_concepts * 5,\n",
    "                epochs=epochs,\n",
    "                batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_explainer = not Path(output_dir_ex / \"map.h5\").exists()\n",
    "if fit_explainer:\n",
    "    exp.fit_explainer(\n",
    "        classifier=model,\n",
    "        X=train.X)\n",
    "else:\n",
    "    exp.explainer.build(input_shape=np.shape(train.X))\n",
    "    exp.explainer.load_weights(str(output_dir_ex / 'map.h5'))\n",
    "\n",
    "X_concepts_kmeans, latent_centers = exp.get_concepts_kmeans(train.X)\n",
    "concept_labels = model(X_concepts_kmeans)\n",
    "latent = exp.explainer.encoder(test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223939ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completeness & importance\n",
    "y_pred = model(test.X)\n",
    "\n",
    "cp = ConceptProperties()\n",
    "map_instance_concept = cp.get_closest_rec_concept_to_instance(test.X, latent.numpy(), latent_centers)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"model\": \"MAP\",\n",
    "    \"accuracy\": cp.get_completness(test.y, y_pred),\n",
    "    \"output_dir\": output_dir,\n",
    "    \"n_concepts\": n_concepts,\n",
    "    \"concept representability\": cp.KL_divergence_performance(test.X[:, :, 0], latent),\n",
    "    \"reconstructed concept representability\": cp.KL_divergence_performance(test.X[:, :, 0],\n",
    "                                                                            map_instance_concept[:, :, 0]),\n",
    "    \"latent_centers\": [latent_centers]\n",
    "}, index=[0]) \\\n",
    "    .to_csv(output_dir / \"completeness_importance_concept_map.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
