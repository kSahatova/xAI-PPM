{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "956eb916",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd67568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skpm import event_logs\n",
    "\n",
    "from ppm.datasets import DatasetSchemas\n",
    "from ppm.utils import parse_args, add_outcome_labels\n",
    "from setup_experiment import setup_dataloaders, setup_model, extract_one_offer_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e89e2",
   "metadata": {},
   "source": [
    "# Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16a37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "NUMERICAL_FEATURES = [\n",
    "    \"accumulated_time\",\n",
    "    \"day_of_month\",\n",
    "    \"day_of_week\",\n",
    "    \"day_of_year\",\n",
    "    \"hour_of_day\",\n",
    "    \"min_of_hour\",\n",
    "    \"month_of_year\",\n",
    "    \"sec_of_min\",\n",
    "    \"secs_within_day\",\n",
    "    \"week_of_year\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb9c3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = r'D:\\PycharmProjects\\xAI-PPM\\configs\\explain_lstm_args_for_op.txt'\n",
    "checkpoints_path = r'D:\\PycharmProjects\\xAI-PPM\\persisted_models\\suffix\\BPI17_rnn_outcome_bpi17.pth'\n",
    "\n",
    "args = parse_args(config_path=config_path)\n",
    "config = vars(args)\n",
    "config[\"log\"] = args.dataset\n",
    "config[\"continuous_features\"]  = (NUMERICAL_FEATURES\n",
    "        if (\n",
    "            args.continuous_features is not None\n",
    "            and \"all\" in args.continuous_features\n",
    "        )\n",
    "        else args.continuous_features\n",
    "    )\n",
    "config[\"checkpoint_path\"] = checkpoints_path\n",
    "config['batch_size'] = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7882c98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Loading checkpoint from D:\\PycharmProjects\\xAI-PPM\\persisted_models\\suffix\\BPI17_rnn_outcome_bpi17.pth succeed!\n"
     ]
    }
   ],
   "source": [
    "log = getattr(event_logs, config[\"log\"])()\n",
    "\n",
    "labels_dict = {\"O_Accepted\": 0, \"O_Cancelled\": 1, \"O_Refused\": 2}\n",
    "column_schema = getattr(DatasetSchemas, config[\"log\"])()\n",
    "labeled_df = add_outcome_labels(log.dataframe, column_schema, labels_dict)\n",
    "\n",
    "# Remove O_Refused to convert the task to a binary classification\n",
    "binary_labeled_df = labeled_df[labeled_df[\"outcome\"] != 2]\n",
    "train_loader, test_loader = setup_dataloaders(config, binary_labeled_df, log.unbiased_split_params)\n",
    "model = setup_model(config, train_loader.dataset.log, model_name='outcome_predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4d8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # a) Extracting sequences that predicted to have \"O_Cancelled\" as an outcome of the given trace\n",
    "\n",
    "# pred_cases_info  =  {'tp': {'ids': [],  'cases': [], 'y_pred': [], 'y_true': []},\n",
    "#                      'tn': {'ids': [],  'cases': [], 'y_pred': [], 'y_true': []},\n",
    "#                      'fp': {'ids': [],  'cases': [], 'y_pred': [], 'y_true': []},\n",
    "#                      'fn': {'ids': [],  'cases': [], 'y_pred': [], 'y_true': []}\n",
    "#                      }\n",
    "\n",
    "# prefix_len = 15\n",
    "# dataset_device = config['device']\n",
    "\n",
    "# for ind, batch in enumerate(test_loader):\n",
    "#     x_cat, x_num, y_cat, _ = batch # type: ignore\n",
    "#     x_cat, x_num, y_cat = x_cat[:, :prefix_len, :], x_num[:, :prefix_len, :], y_cat[:, :prefix_len]\n",
    "#     x_cat, x_num = (x_cat.to(dataset_device), x_num.to(dataset_device))\n",
    "\n",
    "#     attention_mask = (x_cat[..., 0] != 0).long()\n",
    "#     out, _ = model(x_cat=x_cat, x_num=x_num, attention_mask=attention_mask)\n",
    "#     prediction = ((out.squeeze(1)) > 0.5).float()[0, -1].item()\n",
    "    \n",
    "#     case = np.concatenate([x_cat.numpy(), x_num.numpy()], axis=-1)\n",
    "#     y_true = float(y_cat[0, -1].item())\n",
    "#     sample_name = ''\n",
    "#     # Extracting true positives and negatives\n",
    "#     if prediction == y_true:\n",
    "#         if prediction == 0:\n",
    "#             sample_name = 'tn'\n",
    "#         else:\n",
    "#             sample_name = 'tp'\n",
    "#     # Extracting misclassified cases\n",
    "#     else:\n",
    "#         if prediction == 1:\n",
    "#             sample_name = 'fp'\n",
    "#         else:\n",
    "#             sample_name = 'fn'\n",
    "#     pred_cases_info[sample_name]['ids'].append(ind)\n",
    "#     pred_cases_info[sample_name]['cases'].append(case)\n",
    "#     pred_cases_info[sample_name]['y_pred'].append(out.squeeze(1)[0, -1].item())\n",
    "#     pred_cases_info[sample_name]['y_true'].append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a18decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"The number of cases with correct 'O_Cancelled' outcome:\", len(pred_cases_info['tp']['cases']))\n",
    "# print(\"The number of cases with correct 'O_Accepted' outcome:\", len(pred_cases_info['tn']['cases']))\n",
    "# print(\"The number of false positive cases with the outcome 'O_Cancelled':\", len(pred_cases_info['fp']['cases']))\n",
    "# print(\"The number of false negative cases with the outcome 'O_Accepted':\", len(pred_cases_info['fn']['cases']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4cd1f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extracting cases ids from the o_cancelled_cases list with only one offer event in the trace\n",
    "# tp_one_offer_ids, tp_multi_offer_ids = extract_one_offer_cases([trace[0, :, 0] for trace in pred_cases_info['tp']['cases']])\n",
    "# tn_one_offer_ids, tn_multi_offer_ids = extract_one_offer_cases([trace[0, :, 0] for trace in pred_cases_info['tn']['cases']])\n",
    "\n",
    "# fp_one_offer_ids, fp_multi_offer_ids = extract_one_offer_cases([trace[0, :, 0] for trace in pred_cases_info['fp']['cases']])\n",
    "# fn_one_offer_ids, fn_multi_offer_ids = extract_one_offer_cases([trace[0, :, 0] for trace in pred_cases_info['fn']['cases']])\n",
    "\n",
    "# print(f\"Number of cases with one offer: {len(tp_one_offer_ids)} (tp), {len(fp_one_offer_ids)} (fp)\")\n",
    "# print(f\"Number of cases with more than one offer: {len(tp_multi_offer_ids)} (tp), {len(fp_multi_offer_ids)} (fp)\")\n",
    "# print(\"Number of offers per case, frequency: \\n\", \n",
    "#       \"TP:\", list(Counter(tp_multi_offer_ids.values()).items()), '\\n', \n",
    "#       \"FP:\", list(Counter(fp_multi_offer_ids.values()).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a82e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicands_num = 5\n",
    "# tp_explicands  = [pred_cases_info['tp']['cases'][tp_one_offer_ids[i]] for i in range(explicands_num)]\n",
    "# tp_predictions = [pred_cases_info['tp']['y_pred'][tp_one_offer_ids[i]] for i in range(explicands_num)]\n",
    "\n",
    "# tn_explicands  = [pred_cases_info['tn']['cases'][tn_one_offer_ids[i]] for i in range(explicands_num)]\n",
    "# tn_predictions = [pred_cases_info['tn']['y_pred'][tn_one_offer_ids[i]] for i in range(explicands_num)]\n",
    "\n",
    "# fp_explicands  = [pred_cases_info['fp']['cases'][fp_one_offer_ids[i]] for i in range(explicands_num)]\n",
    "# fp_predictions = [pred_cases_info['fp']['y_pred'][fp_one_offer_ids[i]] for i in range(explicands_num)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a070e80",
   "metadata": {},
   "source": [
    "# Generate prototype explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33f1af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_xai.map import Explainer\n",
    "from global_xai.map import ConceptProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c0581d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = train_loader.dataset.log.features\n",
    "total_features_num  = len(all_features.categorical) + len(all_features.numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c54d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_lens = [len(trace) for trace in train_loader.dataset.traces]\n",
    "max_len =  max(trace_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbddcda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('D:/PycharmProjects/xAI-PPM/output')\n",
    "explainer_name = 'map_explainer'\n",
    "\n",
    "output_dir_ex = output_dir / explainer_name\n",
    "output_dir_ex.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "n_concepts = 4\n",
    "epochs = 10\n",
    "\n",
    "exp = Explainer(input_dim=total_features_num,\n",
    "                output_directory=output_dir_ex,\n",
    "                n_concepts=n_concepts,\n",
    "                latent_dim=n_concepts * 5,\n",
    "                epochs=epochs,\n",
    "                batch_size=32,\n",
    "                kwargs={'num_layers': 2,\n",
    "                        'dropout': 0.1,\n",
    "                        'hiddem_dim': 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdfbef03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 97, 1])\n",
      "torch.Size([128, 97, 1])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_explainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PycharmProjects\\xAI-PPM\\global_xai\\map\\explainer_torch.py:104\u001b[0m, in \u001b[0;36mExplainer.fit_explainer\u001b[1;34m(self, classifier, dataloader)\u001b[0m\n\u001b[0;32m     99\u001b[0m x_cat_recon, x_num_recon \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    100\u001b[0m     reconstructed[:, :, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mlong),\n\u001b[0;32m    101\u001b[0m     reconstructed[:, :, \u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    102\u001b[0m )\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# attention_mask_recon = (x_cat_recon[..., 0] != 0).long()\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m out_recon, _ \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_cat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_cat_recon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_num_recon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m sep_loss_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_regularization(latent) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msep_coef\n\u001b[0;32m    111\u001b[0m mse_loss_result \u001b[38;5;241m=\u001b[39m mse_loss(reconstructed, \u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sahat\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\PycharmProjects\\xAI-PPM\\ppm\\models\\models.py:258\u001b[0m, in \u001b[0;36mOutcomePredictor.forward\u001b[1;34m(self, x_cat, x_num, attention_mask, h)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_cat, x_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, h\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 258\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrnn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m: \n",
      "File \u001b[1;32mc:\\Users\\sahat\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\PycharmProjects\\xAI-PPM\\ppm\\models\\common.py:90\u001b[0m, in \u001b[0;36mInLayer.forward\u001b[1;34m(self, cat_x, num_x)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_cols):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# since we use OrderedDict, we can access the embedding layer by index\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(cat_x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 90\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_x\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# add positional encoding\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoding_form \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sahat\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sahat\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sahat\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torch\\nn\\functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "exp.fit_explainer(classifier=model,\n",
    "                  dataloader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_explainer = not Path(output_dir_ex / \"map.h5\").exists()\n",
    "\n",
    "\n",
    "X_concepts_kmeans, latent_centers = exp.get_concepts_kmeans(train.X)\n",
    "concept_labels = model(X_concepts_kmeans)\n",
    "latent = exp.explainer.encoder(test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223939ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completeness & importance\n",
    "y_pred = model(test.X)\n",
    "\n",
    "cp = ConceptProperties()\n",
    "map_instance_concept = cp.get_closest_rec_concept_to_instance(test.X, latent.numpy(), latent_centers)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"model\": \"MAP\",\n",
    "    \"accuracy\": cp.get_completness(test.y, y_pred),\n",
    "    \"output_dir\": output_dir,\n",
    "    \"n_concepts\": n_concepts,\n",
    "    \"concept representability\": cp.KL_divergence_performance(test.X[:, :, 0], latent),\n",
    "    \"reconstructed concept representability\": cp.KL_divergence_performance(test.X[:, :, 0],\n",
    "                                                                            map_instance_concept[:, :, 0]),\n",
    "    \"latent_centers\": [latent_centers]\n",
    "}, index=[0]) \\\n",
    "    .to_csv(output_dir / \"completeness_importance_concept_map.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
